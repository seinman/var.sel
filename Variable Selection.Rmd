---
title: "Variable Selection"
author: "Group 5"
date: "December 12, 2015"
output: pdf_document
---

In order to find the outliers, we will train a model using a section of the dataset that does not include our first 400 observations. We will then fit that model to the dataset we are interested in. This will avoid the 50 outliers from impacting the estimated coefficients in such a way as to mask themselves. We have therefore used observations 401 to 3000 of the synthetic regression data to train a model, which we will test on observations 1 to 400.

We will use a stepwise algorithm in order to find out which of the variables to include in the dataset. The major flaw in this method is that it fails to take into account correlations between the different variables. In order to get around this issue, we create groups of highly correlated variables. Therefore instead of, for instance, making a stepwise choice whether to include variable one, variable two, or variable three, the algorithm chooses whether to include variables one or two *and* three together.

```{r}
file <- '/home/beeb/Documents/Data_Science/Data/Stat/'
library(ggplot2)
library(dplyr)
setwd(file)
synth.reg.test <- read.table('synthetic_regression.txt', header = TRUE, nrows= 400)
synth.reg.train <- read.table('synthetic_regression.txt', header = TRUE, nrows = 3000)
synth.reg.train <- synth.reg.train[401:3000,]
```

This section of code identifies the correlated x's:

```{r}

# This bit of code figures out which of the xs need to be put in groups together
# The first thing we're going to do is see if any of the x's are correlated
cors <- cor(synth.reg.train[2:ncol(synth.reg.train)])
m <- ncol(cors)

# Pick out those that have correlation above 0.5
together <- apply(abs(cors)>0.5, 2, which)

```

We now have a list, 'together', which contains all the variables that should go together. We will scan through this list and see which groups of variables we can add to our current set of variables in order to provide a model with the highest log likelihood.

```{r}
# Initialise a dataframe for adding variables to and a list to show which groups were added
currentmod <- data.frame(t = synth.reg.train$t)
incvars <- list()

# Stepwise!
# Take the first 50 most important variables (we can examine subsets later on)
for(k in 1:50) {
  likelihoods <- sapply(together, function(y) {
      mod <- cbind(currentmod, select(synth.reg.train, one_of(names(y)))) 
      model <- lm(t ~ ., data = mod)
      return(logLik(model))
  })
  # Choose the variable which will give the best log likelihood
  bestvar <- which(likelihoods == max(likelihoods))
  incvars[[k]] <- bestvar

  # Move the best variables from the list of vars under consideration to the dataframe of selected variables
  together <- together[setdiff(1:length(together), bestvar)]
  currentmod <- cbind(currentmod, select(synth.reg.train, one_of(names(bestvar))))
}

```

We now have a list of the top 50 groups of variables (59 variables in total) that impact on t. We will now create a series of linear models on the training data, test them on the testing data, and choose a model which provides a high R^2 on the test data.

```{r}
  # This bit exists due to the complication of needing to treat certain variables in groups
  # That is, highly correlated variables should go together
  # 'Steps' will tell us; first take the first three vars; then the next two vars; then
  # one by itself ; etc etc.
  steps <- cumsum(sapply(incvars, length))  
  incvars2 <- unlist(incvars)
  collect.r2 <- rep(0, length(steps))
  num.outliers <- rep(0, length(steps))
  j <- 1
  
  for(i in steps) {
    currentmod <- select(synth.reg.train, t, one_of(names(incvars2)[1:i]))
    model <- lm(t ~ ., data = currentmod)
    assign(paste0('model', j), model)
    synth.reg.test$predvals <- predict(model, newdata = synth.reg.test)
    
    #We collect the R^2 of using the training model on the testing data.
    # Not sure if there's an automatic way to do this.
    # Also mark out the points with low likelihood
    synth.reg.test$residuals <- synth.reg.test$predvals - synth.reg.test$t
    
    ressumsquare <- sum((synth.reg.test$residuals)**2)
    totsumsquare <- sum((synth.reg.test$t - mean(synth.reg.test$t))**2)
    r.squared <- 1 - (ressumsquare/totsumsquare)
    collect.r2[j] <- r.squared
    
    # We create a cutoff - a 1.96 standard deviation confidence interval, using the standard deviations from the training dataset, and we mark off those that fall outside that interval
    cutoff <- sd(model$residuals) * 1.96
    synth.reg.test$cutoff <- 0
    synth.reg.test$cutoff[abs(synth.reg.test$residuals) > cutoff] <- 1
    num.outliers[j] <- sum(synth.reg.test$cutoff)
    assign(paste0('synth.reg.test', j), synth.reg.test)
    
    # Now make a graph showing predicted values vs actual values
    plottest <- ggplot(data = synth.reg.test, aes(x = predvals, y = t, colour = cutoff)) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1) + 
    geom_abline(intercept = cutoff, slope = 1) +
    geom_abline(intercept = -cutoff, slope = 1) +      
    ggtitle(paste('first', i, 'vars, R2:', round(r.squared, 3), 'Observations above cutoff:', sum(synth.reg.test$cutoff)))
   assign(paste0('plottest', j), plottest)
  
   # And another graph showing the size of the residuals
  plottest.res <- ggplot(data = synth.reg.test, aes(y = abs(residuals), x = rownames(synth.reg.test), colour = cutoff)) + geom_point() +
    geom_hline(yintercept = 1.96 * sd(model$residuals), colour = 'deeppink2') +
    ggtitle(paste('first', i, 'vars, R2:', round(r.squared, 3), 'Observations above cutoff:', sum(synth.reg.test$cutoff))) +
    xlab('') +
    ylab('residual size')
  assign(paste0('plottest.res', j), plottest.res)
  
  j <- j + 1
  }

```  

We now have a series of graphs which show us how our residuals change depending on the size of our models. We choose the model which gives the highest R^2^ when used on the testing dataset. We find it is model 7.

```{r}
  which(collect.r2 == max(collect.r2))
  summary(model7)
  plottest7
  plottest.res7
```

The last step is to create a list of which observations are above the cutoff value. As we see from the graphs above, there is not a clear point separation between outliers and non-outliers. I have therefore included in my list all the observations above the cutoff value, although at the margins the choice of whether to list a certain observation as an outlier or not is somewhat arbitrary. 'Index' captures the row numbers of these observations.

```{r}
  outliers <- mutate(synth.reg.test7, index = rownames(synth.reg.test7)) %>%
    filter(cutoff == 1) %>%
    arrange(residuals) %>%
    select(t, predvals, residuals, index)
  
  outliers
  
```
  
